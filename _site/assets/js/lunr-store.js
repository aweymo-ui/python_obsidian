var store = [ 
    
    
    { 
        "url": "/content/1_background.html",
        "title": "Background",
        "text": "Hello, my name is Andrew Weymouth and I have worked with the University of Idaho Library as the Digital Initiatives Librarian in the Center for Digital Inquiry and Learning (CDIL) department since the fall of 2023. My work generally consists of creating and maintaining our digital collections, helping to rethink processes and introducing new digital scholarship tools to the department. &#10042; CollectionBuilder browse site and CollectionBuilder template interface. Established in 2008, the CDIL maintains over 130 digital collections built from the open-source frameworks CollectionBuilder and Oral History as Data (OHD). The latter enables researchers to explore oral history collections through customized subject tags created by the transcriber depending on the recording’s content and themes. Oral History as Data tagging interface with tags and how they are visualized within two recordings below. &#10042; This project was initially inspired by discovering gaps in our oral history transcripts following a data migration over the winter of 2023. Because of the volume of the material that needed generating, it was worthwhile to rethink workflows for overall efficiency and accuracy."
    },
    { 
        "url": "/content/2_challenges.html",
        "title": "Challenges",
        "text": "The time-intensive nature of transcription has made many oral history collections an undervalued format in digital initiatives. Accessibility standards require both accurate transcriptions and a keyboard navigable interface which the OHD template, created by Devin Becker, addresses. Oral History as Data tagging interface and keyword searching functionality. Despite this front end advancement, the initial transcription process has remained a significant hurdle. While machine learning speech-to-text has improved, earlier free tools were inadequate, and manual transcription can be tedious and prone to errors without close supervision. Tagging, handled by student workers, also faced issues like uncontrolled vocabulary, knowledge gaps, and biases from linear listening. &#10042; Challenges of Linear Listening Visualization Linear listening, or creating tags by listening to an oral history collection from beginning to end, may mislead transcribers by establishing repeating themes that don’t occur across the collection or missing themes that only begin to appear in later recordings. The name of this presentation, distant listening, is an alternate approach which text mines combined transcripts and generates tags before the student worker begins the copy editing process, with the goal of producing richer, more accurate data, ultimately allowing researchers to identify more connections across entire oral history collections. &#10042;"
    },
    { 
        "url": "/content/3_process.html",
        "title": "Process",
        "text": "Contents: Overview | Transcription | Python Text Mining | Linking Primary Tag Sheet to Individual Transcripts | Copyediting Workflow Visualization Overview To summarize the process: Audio is transcribed into CSV files by Premiere CSVs are made into individual Google Sheets and also added to the Python Transcription Mining Tool Within the tool, these items are concatenated and searched for all associated words and phrases built into the tool under different tag categories The tool generates a tally of the these words and phrases, which is used to create the “Primary Tag Sheet” in another Google Sheet Using the Apps Script function, all individual transcripts are linked to the primary tag sheet so their tag fields are automatically generated New categories or associated words can be added or removed to the Primary Tag Sheet and these changes can be implemented across all individual transcripts by simply re-running the code Individual changes can be implemented during the student worker led copy editing process to catch any data driven errors &#10042; Transcription Moving away from the Otter.AI the department had been working with, I tested Adobe Premiere’s transcription tools and found it uniquely well-suited for the OHD framework with advantages including dramatically increased accuracy in differentiating speakers and transcribing dialogue, significantly faster transcription speed, from one hour long recording every two to three business days up to twenty hour recordings a day and high privacy standards with GDPR compliance, ensuring all transcription material is stored locally and not uploaded to the cloud.[1] Example of transcript CSV formatting as it exports from Adobe Premiere That said, the tool is not perfect. While modern recordings in good conditions have extremely high transcription accuracy, poor quality recordings or interviews between two similar sounding people can require significant copyediting. Recent work by the Matt Miller of the Library of Congress has me very interested in creating custom speech to text tools using Whisper(.cpp) to possibly help improve on these inaccuracies.[2] &#10042; Python Text Mining After initial tests using the web based text mining tool Voyant, I wanted to create a text mining tool from scratch using Python that would allow me to identify specific words and phrases, create custom tagging categories and “stopwords”(words removed from text before processing and analysis) for each collection. Once the CSVs of the transcript are added to a folder in the Python workspace, the code imports text mining libraries such as Pandas, NLTK, TextBlob, and regular expressions for processing. Extract of the Python code in the Geographic&gt;Finland section of the text mining tool Below this header material in the Python file are three categories of tags: general, geographic and custom, which contain twenty subsections each and these subsections contain 50 associated words or phrases that are being identified throughout the combined corpus and ultimately tallied to produce the output shown here: &#10042; Example of Text Mining Tool Output for the Rural Women's History Project See Appendix 1 for an excerpt of the this script or visit the Git to view in full. Linking Primary Tag Sheet to Individual Transcripts This data is then entered into a “primary tag sheet” also in Google Sheets. After formatting their transcripts, the student worker opens the Apps Script extension and enters a string of code (see Appendix 2). After making two minor adjustments based on the URL of their transcript, it will be linked to the Primary Tag Sheet. &#10042; Copyediting This process is not intended to replace human transcribers, instead this aims to enhance the role of human transcribers by shifting the focus from manual tagging to copy editing, thus reducing repetitive tasks. Student workers are encouraged to modify tag names, adjust associated words, and create new categories based on trends identified in the primary tag sheet. This approach not only diversifies the tasks of student workers beyond transcription—often monotonous, with little to highlight on a CV—and enables them to engage in coding and instantly see the impact of their modifications. Other advantages include: All tags use a controlled vocabulary. Tagging is more accurate, detailed, and relevant, helping researchers quickly identify thematic connections. Tagging establishes a knowledge framework relevant to the collection that transcribers might lack in historical, scientific, or regional contexts key to the recordings."
    },
    { 
        "url": "/content/4_findings.html",
        "title": "Findings and Conclusion",
        "text": "Pre and Post Process Tagging Visualization Regarding the limitations of data-driven, human-edited tagging, program managers should clarify that automated tags are only a starting point and may be incorrectly applied, missing, or require broader application across transcripts. Also, the amount of detail this process accrues is drastic and one could argue that the density of the data now makes it difficult for the researcher to navigate, especially on mobile devices, which remains a topic for ongoing refinement. My hope is that utilizing machine learning, Python, and JavaScript approaches will make digitizing these resources more efficient and accessible, promoting their preservation and availability to the public."
    },
    { 
        "url": "/content/5_references_apendices.html",
        "title": null,
        "text": "Contents: Notes | Appendix 1. Excerpt of Python Text Mining Tool | Appendix 2. Apps Script Example for Linking Transcript to Primary Tag Sheet | About the Author &#10042; Notes [1] Speech to Text in Premiere Pro FAQ. Adobe; [cited 2024 Jul 8]. Available from: https://helpx.adobe.com/content/help/en/premiere-pro/using/speech-to-text-faq.html [2] Matt Miller. “Lomax Whisper,” September 12, 2024. https://thisismattmiller.com/post/lomax-whisper/ Appendix 1. Excerpt of Python Text Mining Tool import pandas as pd import string from nltk.corpus import stopwords from collections import Counter import re from textblob import TextBlob Download NLTK stopwords data import nltk nltk.download('stopwords') Define preprocess_text function def preprocess_text(text): if isinstance(text, str): # Check if text is a string text = re.sub(r'\\b\\w{1,4}\\b', '', text) # Remove short words (length &lt;= 4) text = text.translate(str.maketrans('', '', string.punctuation)) text = text.lower() # Convert text to lowercase else: text = '' # Replace NaNs with an empty string return text Load stopwords for both Spanish and English stop_words_spanish = set(stopwords.words('spanish')) stop_words_english = set(stopwords.words('english')) Combine both sets of stopwords stop_words = stop_words_spanish.union(stop_words_english) import os Directory containing CSV files directory = 'C:\\\\Users\\\\aweymouth\\\\Documents\\\\Github\\\\transcript_mining_base\\\\CSV' List of CSV file names file_names = [ 'rwhp070.csv', 'rwhp075.csv', 'rwhp079.csv', 'rwhp083.csv', 'rwhp088.csv', 'rwhp109.csv', 'rwhp123.csv', 'rwhp174.csv', 'rwhp225.csv', 'rwhp261.csv', 'rwhp277.csv', 'rwhp277.csv', 'rwhp297.csv', 'rwhp320.csv', 'rwhp323.csv', 'rwhp378.csv', 'rwhp385.csv', 'rwhp410.csv', 'rwhp418.csv', 'rwhp420.csv', 'rwhp421.csv', 'rwhp422.csv', 'rwhp425.csv', 'rwhp426.csv', 'rwhp427.csv' ] Construct file paths using os.path.join() file_paths = [os.path.join(directory, file_name) for file_name in file_names] dfs = [pd.read_csv(file_path, encoding='utf-8') for file_path in file_paths] Concatenate text data from all dataframes into a single corpus corpus = '' for df in dfs: text_series = df['text'].fillna('').astype(str).str.lower().str.strip() # Extract and preprocess text column corpus += ' '.join(text_series) + ' ' # Concatenate preprocessed text with space delimiter Preprocess the entire corpus cleaned_corpus = preprocess_text(corpus) Remove stopwords from the corpus filtered_words = [word for word in cleaned_corpus.split() if word not in stop_words and len(word) &gt;= 5] Count the frequency of each word word_freq = Counter(filtered_words) Get top 100 most frequent distinctive words with occurrences top_distinctive_words = word_freq.most_common(100) === General Section === from collections import Counter import re def find_agriculture_terms(corpus): # Define a list of agriculture-related terms agriculture_terms = [\"harvest\", \"tractor\", \"acreage\", \"crop\", \"livestock\", \"farm field\", \"barn building\", \"ranch\", \"garden\", \"orchard\", \"dairy\", \"cattle\", \"poultry\", \"equipment\", \"fertilizer\", \"seed\", \"irrigation\", \"plow\", \"farmhand\", \"hoe\", \"shovel\", \"milking\", \"hay\", \"silage\", \"compost\", \"weeding\", \"crop rotation\", \"organic\", \"gmo\", \"sustainable\", \"farming\", \"rural\", \"homestead\", \"tilling\", \"wheat\", \"corn maize\", \"soybean\", \"potato\", \"apple fruit\", \"berry\", \"honey\", \"apiary\", \"pasture\", \"combine harvester\", \"trailer\", \"baler\", \"thresher\"] # Initialize a Counter to tally occurrences of agriculture-related terms agriculture_word_freq = Counter() # Tokenize the corpus to handle multi-word expressions tokens = re.findall(r'\\b\\w+\\b', corpus.lower()) # Iterate over each token in the corpus for word in tokens: # Check if the token is an agriculture-related term if word in agriculture_terms: agriculture_word_freq[word] += 1 # Return the top 50 most common agriculture-related terms return agriculture_word_freq.most_common(50) Call the function to find agriculture-related terms in the corpus top_agriculture_terms = find_agriculture_terms(corpus) Print the top 50 agriculture-related terms print(\"## agriculture\") for word, count in top_agriculture_terms: print(f\"{word.capitalize()}: {count}\") Appendix 2. Apps Script Example for Linking Transcript to Primary Tag Sheet function fillTags() { // Get the active spreadsheet var spreadsheet = SpreadsheetApp.getActiveSpreadsheet(); // Get the transcript sheet by name var transcriptSheet = spreadsheet.getSheetByName(\"Callison3\"); if (!transcriptSheet) { Logger.log(\"Transcript sheet not found\"); return; } // Set the header in cell E1 to \"tags\" transcriptSheet.getRange(\"E1\").setValue(\"tags\"); // Get the tags spreadsheet by URL var tagsSpreadsheet = SpreadsheetApp.openByUrl(\"https://docs.google.com/spreadsheets/d/1soOfgdAjik_TL8WX9dDV9BaFb1RQJc8_BVu7sBGnNUE/edit?gid=419710039#gid=419710039\"); if (!tagsSpreadsheet) { Logger.log(\"Tags spreadsheet not found\"); return; } // Get the tags sheet within the tags spreadsheet var tagsSheet = tagsSpreadsheet.getSheetByName(\"tags\"); if (!tagsSheet) { Logger.log(\"Tags sheet not found\"); return; } // Get the range of the transcript column var transcriptRange = transcriptSheet.getRange(\"D2:D\" + transcriptSheet.getLastRow()); var transcriptValues = transcriptRange.getValues(); // Get the range of example words and tags in the tags sheet var exampleWordsRange = tagsSheet.getRange(\"B2:B\" + tagsSheet.getLastRow()); var tagsRange = tagsSheet.getRange(\"A2:A\" + tagsSheet.getLastRow()); var exampleWordsValues = exampleWordsRange.getValues(); var tagsValues = tagsRange.getValues(); // Create a map of example words to tags var tagsMap = {}; for (var i = 0; i &lt; exampleWordsValues.length; i++) { var word = exampleWordsValues[i][0].toLowerCase(); var tag = tagsValues[i][0]; tagsMap[word] = tag; } // Initialize an array to store the tags for each transcript entry var transcriptTags = []; // Loop through each transcript entry for (var i = 0; i &lt; transcriptValues.length; i++) { var text = transcriptValues[i][0]; var uniqueTags = []; if (typeof text === 'string') { // Use regular expression to extract words and handle punctuation var words = text.match(/\\b\\w+['-]?\\w*|\\w+['-]?\\w*\\b/g); // Check each word in the transcript entry against the tags map if (words) { for (var j = 0; j &lt; words.length; j++) { var word = words[j].toLowerCase().replace(/[.,!?;:()]/g, ''); var singularWord = word.endsWith('s') ? word.slice(0, -1) : word; if (tagsMap.hasOwnProperty(word) &amp;&amp; !uniqueTags.includes(tagsMap[word])) { uniqueTags.push(tagsMap[word]); } else if (tagsMap.hasOwnProperty(singularWord) &amp;&amp; !uniqueTags.includes(tagsMap[singularWord])) { uniqueTags.push(tagsMap[singularWord]); } } } } // Add the determined tags to the array transcriptTags.push([uniqueTags.join(\";\")]); } // Get the range of the tags column in the transcript sheet, starting from E2 var tagsColumn = transcriptSheet.getRange(\"E2:E\" + (transcriptTags.length + 1)); // Set the values in the tags column to the determined tags tagsColumn.setValues(transcriptTags); } About the Author Andrew Weymouth is the Digital Initiatives Librarian at University of Idaho, specializing in static web design to curate the institution’s special collections and partner with faculty and students on fellowship projects. His work spans digital scholarship projects at the universities of Oregon and Washington and the Tacoma Northwest Room archives, including long form audio public history projects, architectural databases, oral history and network visualizations. He writes about labor, architecture, underrepresented communities and using digital methods to survey equity in archival collections."
    },
    { 
        "url": "/",
        "title": "Home",
        "text": "Slides Git Repository for Transcript Text Mining Tool Overview This presentation will provide a walkthrough of new processes for creating subject tags across complete oral history collections developed at the U of I Center for Digital Inquiry and Learning over the summer of 2024. It details a workflow enabling student workers to run, modify, and expand tags during copyediting, aiming to enhance accuracy and ultimately help researchers identify connections between recordings. We’ll cover the workflow, challenges it addresses and the limitations of data-driven, human-edited tagging. Contents: Background Challenges Process Findings References and Appendices Content: CC BY-NC-ND 4.0 Andrew Weymouth 2024 (get source code). Theme: Variation on workshop-template-b by evanwill"
    }];
